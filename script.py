import requests
from bs4 import BeautifulSoup
import os
import time

BLOG_URL = "https://blog.goo.ne.jp/shinanren"

# User-Agent ã‚’å¤‰æ›´ã—ã€Referer ã‚’è¨­å®šï¼ˆãƒ–ãƒ©ã‚¦ã‚¶çµŒç”±ã‚’è£…ã†ï¼‰
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Linux x86_64; rv:91.0) Gecko/20100101 Firefox/91.0",
    "Referer": "https://www.google.com/",
    "Accept-Language": "ja,en-US;q=0.9,en;q=0.8"
}

def get_latest_article():
    """æœ€æ–°è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒªãƒ³ã‚¯ã‚’å–å¾—ã™ã‚‹ï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰"""
    print("ğŸ” ãƒ–ãƒ­ã‚°ã«ã‚¢ã‚¯ã‚»ã‚¹ä¸­...")

    session = requests.Session()
    session.headers.update(HEADERS)

    for attempt in range(3):  # 3å›ã¾ã§ãƒªãƒˆãƒ©ã‚¤
        try:
            response = session.get(BLOG_URL)
            print(f"âœ… HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}")

            if response.status_code == 200:
                break  # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
            else:
                print(f"âš ï¸ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}ã€‚5ç§’å¾…æ©Ÿã—ã¦å†è©¦è¡Œã—ã¾ã™...")
                time.sleep(5)
        except requests.exceptions.RequestException as e:
            print(f"âŒ ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            time.sleep(5)

    if response.status_code != 200:
        print("âŒ ã™ã¹ã¦ã®ãƒªãƒˆãƒ©ã‚¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return None, None

    soup = BeautifulSoup(response.text, "html.parser")
    print("ğŸ” å–å¾—ã—ãŸHTMLã®ä¸€éƒ¨:")
    print(soup.prettify()[:1000])  # æœ€åˆã®1000æ–‡å­—ã ã‘å‡ºåŠ›

    # è¨˜äº‹ãƒªã‚¹ãƒˆã® div ã‚’æ¢ã™ï¼ˆæ­£ã—ã„ã‚¯ãƒ©ã‚¹åã«ä¿®æ­£ï¼‰
    article_list = soup.find("div", class_="blog_index_list")
    if article_list is None:
        print("âŒ è¨˜äº‹ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ï¼ˆ`div.blog_index_list` ãŒè¦‹ã¤ã‹ã‚‰ãªã„ï¼‰")
        return None, None

    # è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ãƒªãƒ³ã‚¯ã‚’å–å¾—
    link_tag = article_list.find("div", class_="blog_index_title").find("a")
    if link_tag is None:
        print("âŒ è¨˜äº‹ã®ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ï¼ˆ`div.blog_index_title > a` ãŒè¦‹ã¤ã‹ã‚‰ãªã„ï¼‰")
        return None, None

    latest_link = link_tag["href"]
    latest_title = link_tag.text.strip()

    print(f"âœ… æœ€æ–°è¨˜äº‹: {latest_title} ({latest_link})")
    return latest_link, latest_title

def main():
    print("ğŸš€ `script.py` ãŒå®Ÿè¡Œã•ã‚Œã¾ã—ãŸï¼")
    latest_link, latest_title = get_latest_article()
    if latest_link is None:
        print("âš ï¸ æœ€æ–°è¨˜äº‹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return
    print("ğŸ†• æœ€æ–°è¨˜äº‹ã®æƒ…å ±ãŒå–å¾—ã•ã‚Œã¾ã—ãŸï¼")

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
if __name__ == "__main__":
    main()

if __name__ == "__main__":
    main()
